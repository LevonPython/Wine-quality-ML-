{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wine Quality using Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules that will be used in process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\anaconda3\\lib\\site-packages (19.2.3)\n",
      "Requirement already satisfied: install in c:\\users\\user\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: cvxopt in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pip install cvxopt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import cvxopt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# from pandas.core.common import SettingWithCopyWarning\n",
    "# warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from numpy import mean, std,isnan, asarray, polyfit\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier #SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,recall_score, precision_score,classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data set (csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have got df_final dataframe in our Getting_best_dataframe file. So here we can import our save file.\n",
    "#### df_final = pd.read_csv('Dataframe_final.csv')\n",
    "#### df_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequalityN.csv\")\n",
    "# df.sample(5)                  #shows 5 random choosen rows\n",
    "# df.head(5)                    #shows first 5 rows from data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting nomalized data from given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_correcting(data_):\n",
    "    \n",
    "    \"\"\" In dataset some values for fixed acidity, volatile acidity,\n",
    "    citric acid, residual sugar, chlorides, pH, sulphates are missing. \n",
    "    Solve this problem by filling null values with mean values of train dataframe.\n",
    "     irst of all we need to change text values of wine type to the 0 and 1.\n",
    "    Then we need to get train data and Fill Nan values by this data mean.\"\"\"\n",
    "    \n",
    "    data_[\"type\"].replace({\"red\": 0, \"white\": 1}, inplace=True) # \"RED\": 0, \"WHITE\": 1       \n",
    "    train_df = data_.sample(frac=0.8, random_state=42)\n",
    "    df.fillna(train_df.mean(axis=0), inplace=True)\n",
    "    \n",
    "    \"\"\" Now we have 1599 red and 4898 white wine rows\n",
    "    You can check it by this:\n",
    "    dups_color = df.pivot_table(index=['type'], aggfunc='size')\n",
    "    dups_color \"\"\"\n",
    "    \n",
    "    return data_\n",
    "\n",
    "df = data_correcting(df)\n",
    "\n",
    "def oversampling_data(data_):\n",
    "    \n",
    "    \"\"\" Share of white wines is 75%. So we deside to oversampling data with random choosen red wine data.\n",
    "    As in the future we can have other share of white and red wines, we get this solution for all possible cases. \"\"\"\n",
    "    \n",
    "    red_count = df.loc[data_['type'] == 0].count()[0]\n",
    "    white_count = df.loc[data_['type'] == 1].count()[0]\n",
    "    if white_count > red_count:\n",
    "        for i in range((white_count-red_count)):\n",
    "            df1 = data_.loc[data_['type'] == 0].sample()\n",
    "            data_ = data_.append(df1)\n",
    "    else:\n",
    "        for i in range((red_count-white_count)):\n",
    "            df1 = data_.loc[df['type'] == 1].sample()\n",
    "            data_ = data_.append(df1)\n",
    "            \n",
    "    \"\"\" Now combining fixed acidity, volatile acidity and citric acid into one variable total_acidity\n",
    "    and our target variable into two classes: low quality-->0 (3, 4, 5)  and high quality-->1 (6,7,8,9)\"\"\"\n",
    "    \n",
    "    data_[\"total_acidity\"]= data_['fixed acidity']+data_['volatile acidity']+data_['citric acid']\n",
    "    quaity_mapping = { 3 : 0, 4 : 0, 5: 0, 6 : 1, 7: 1, 8 : 1, 9 : 1}\n",
    "    data_[\"quality\"] =  data_[\"quality\"].map(quaity_mapping)\n",
    "    \n",
    "    \"\"\"You can check that it works by this\n",
    "    dups_color = df.pivot_table(index=['type'], aggfunc='size')\n",
    "    dups_color\n",
    "    Now we have 4898 of red and 4898 of white wines data \"\"\"\n",
    "    \n",
    "    return data_\n",
    "    \n",
    "\n",
    "# From all EDA analyze we can see that there are some outliers. So we have 2 variants\n",
    "# 1. Remove this outliers.\n",
    "# 2. Replace them with max/min values, so they may contain good values for other features and this variant will save their values\n",
    "# The whole analyse we have shown in the initial stage of project. So here we will show only the result of our final decisioans.\n",
    "# 3. Combine our target variable into two classes: low quality (3, 4, 5)  and high quality (6,7,8,9)\n",
    "\n",
    "\n",
    "def first_data(data_):\n",
    "    lower_limit = data_[\"free sulfur dioxide\"].mean() - 3*data_[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = data_[\"free sulfur dioxide\"].mean() + 3*data_[\"free sulfur dioxide\"].std()\n",
    "    df2 = data_[(data_[\"free sulfur dioxide\"] > lower_limit) & (data_[\"free sulfur dioxide\"] < upper_limit)]\n",
    "    lower_limit = df2['total sulfur dioxide'].mean() - 3*df2['total sulfur dioxide'].std()\n",
    "    upper_limit = df2['total sulfur dioxide'].mean() + 3*df2['total sulfur dioxide'].std()\n",
    "    df3 = df2[(df2['total sulfur dioxide'] > lower_limit) & (df2['total sulfur dioxide'] < upper_limit)]\n",
    "    lower_limit = df3['residual sugar'].mean() - 3*df3['residual sugar'].std()\n",
    "    upper_limit = df3['residual sugar'].mean() + 3*df3['residual sugar'].std()\n",
    "    df4 = df3[(df3['residual sugar'] > lower_limit) & (df3['residual sugar'] < upper_limit)]\n",
    "    \n",
    "    return df4\n",
    "    \n",
    "dataframe_1 = first_data(oversampling_data(df)).copy()\n",
    "\n",
    "def second_data(data_):\n",
    "    lower_limit = data_[\"free sulfur dioxide\"].mean() - 3*data_[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = data_[\"free sulfur dioxide\"].mean() + 3*data_[\"free sulfur dioxide\"].std()\n",
    "    df2_repl = data_\n",
    "    \n",
    "    def replace_outliers(arr):\n",
    "        arr = np.array(arr)\n",
    "        upper = arr.mean() + 3 * arr.std()\n",
    "        lower = arr.mean() - 3 * arr.std()\n",
    "        arr[(arr > upper)] = upper\n",
    "        arr[(arr < lower)] = lower\n",
    "        \n",
    "        return arr\n",
    "    \n",
    "    df2_repl[\"free sulfur dioxide\"] = replace_outliers(df2_repl[\"free sulfur dioxide\"])\n",
    "    df2_repl[\"total sulfur dioxide\"] = replace_outliers(df2_repl[\"total sulfur dioxide\"])\n",
    "    df2_repl[\"residual sugar\"] = replace_outliers(df2_repl[\"residual sugar\"])\n",
    "\n",
    "    lower_limit = df2_repl[\"free sulfur dioxide\"].mean() - 3*df2_repl[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = df2_repl[\"free sulfur dioxide\"].mean() + 3*df2_repl[\"free sulfur dioxide\"].std()\n",
    "    \n",
    "    return df2_repl\n",
    "\n",
    "dataframe_2 = second_data(oversampling_data(df)).copy()\n",
    "\n",
    "\n",
    "def lst_of_dataframes(d1, d2):\n",
    "    \n",
    "    \"\"\" list of dataframe_1 and dataframe_2 \"\"\"\n",
    "    \n",
    "    df_list = [d1, d2] \n",
    "    for i in range(len(df_list)):\n",
    "        df_ = df_list[i]\n",
    "        df_final = df_[[\"total_acidity\", \"chlorides\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"]]\n",
    "        df_list[i] = df_final\n",
    "        \n",
    "    return df_list\n",
    "        \n",
    "def get_dataset(dataframe):\n",
    "    \n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def checking_better_dataframe(lst):\n",
    "    \n",
    "    #lst = lst_of_dataframes(dataframe_1, dataframe_2)\n",
    "    \n",
    "    \"\"\" This function will get accuracy for two dataframes that we have, compare them\n",
    "    and return the dataframe wich gives us better accuracy. \"\"\"\n",
    "    \n",
    "    l_accuracy = []\n",
    "    \n",
    "    for i in range(len(lst)):\n",
    "        X, y = get_dataset(lst[i])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "        log_reg = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                       multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)\n",
    "        log_reg.fit(X_train,y_train)\n",
    "        y_hat = log_reg.predict(X_test)        \n",
    "        cm = confusion_matrix(y_hat,y_test)\n",
    "        accuracy = metrics.accuracy_score(y_hat,y_test)\n",
    "        l_accuracy.append(accuracy)\n",
    "#         print(f'Accuracy of dataframe_{i+1} is {accuracy}')\n",
    "#         print(f'log_reg.intercept_ of dataframe_{i+1} is {log_reg.intercept_}')\n",
    "#         print(f'log_reg.coef_ of dataframe_{i+1} is {log_reg.coef_}')\n",
    "#         print(f'confusion_matrix of dataframe_{i+1} is {cm}\\n')\n",
    "    if l_accuracy[0] > l_accuracy[1]:\n",
    "        \n",
    "        return lst[0]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return lst[1]\n",
    "        \n",
    "df_final = checking_better_dataframe(lst_of_dataframes(dataframe_1, dataframe_2))[[\"total_acidity\", \"chlorides\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have 2 datasets for modeling\n",
    "#### 1.1) dataframe_1 (where outliers removed, quality scaled to 2 types)\n",
    "#### 1.2) dataframe_2 (where outliers replaced with mean values, quality scaled to 2 types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic regression\n",
    "# 2. Cross-validation - KFold\n",
    "# 3. RandomForestClassifier\n",
    "# 4. SVM\n",
    "# 5. Kernel SVM\n",
    "# 6. Gaussian Kernel\n",
    "# 7. Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the dataset transformation function\n",
    "def get_dataset(dataframe):\n",
    "\n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def log_regression(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    #Logistic regression\n",
    "    log_reg = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                       multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)\n",
    "    log_reg.fit(X_train,y_train)\n",
    "    y_hat = log_reg.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_hat,y_test)\n",
    "    cm = confusion_matrix(y_hat,y_test)\n",
    "    # Let's predict target values for test dataset and check model accuracy\n",
    "    print('Logistic regression')\n",
    "    print(f'Accuracy of dataframe is: {accuracy}')\n",
    "    print(f'log_reg_intercept of dataframe is: {log_reg.intercept_}')\n",
    "    print(f'log_reg_coef of dataframe is: {log_reg.coef_}')\n",
    "    print(f'confusion_matrix of dataframe is:\\n {cm}\\n')\n",
    "\n",
    "#Cross-validation - KFold\n",
    "def k_fold_model(dataframe, k):\n",
    "    X, y = get_dataset(dataframe)\n",
    "\n",
    "    # retrieve the model to be evaluate\n",
    "    def get_model():\n",
    "        model = LogisticRegression()\n",
    "        return model\n",
    "\n",
    "    # evaluate the model using a given test condition\n",
    "    def evaluate_model(cv):\n",
    "        # get the dataset\n",
    "        #X, y = fit_dataset(dataframe)\n",
    "        # get the model\n",
    "        model = get_model()\n",
    "        # evaluate the model\n",
    "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        # return scores\n",
    "        return mean(scores), scores.min(), scores.max()\n",
    "\n",
    "\n",
    "    print('Cross-validation - KFold')\n",
    "    # define folds to test\n",
    "    folds = range(2, k+1)\n",
    "\n",
    "    # record mean and min/max of each set of results\n",
    "    means, mins, maxs = list(),list(),list()\n",
    "    # evaluate each k value\n",
    "    for k in folds:\n",
    "        # define the test condition\n",
    "        cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "        # evaluate k value\n",
    "        k_mean, k_min, k_max = evaluate_model(cv)\n",
    "        # report performance        \n",
    "        print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "        # store mean accuracy\n",
    "        means.append(k_mean)\n",
    "        # store min and max relative to the mean\n",
    "        mins.append(k_mean - k_min)\n",
    "        maxs.append(k_max - k_mean)\n",
    "    # calculate the ideal test condition\n",
    "    ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "    print()\n",
    "    print('Ideal: %.3f' % ideal)\n",
    "    print()\n",
    "\n",
    "#RandomForestClassifier\n",
    "def rand_forest(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    rf=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                           criterion='gini', max_depth=None, max_features='auto',\n",
    "                           max_leaf_nodes=None, max_samples=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_jobs=None, oob_score=False, random_state=None,\n",
    "                           verbose=0, warm_start=False)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred=rf.predict(X_test)\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    accuracy2 = metrics.accuracy_score(y_pred, y_test)\n",
    "    cm2 = confusion_matrix(y_pred,y_test)\n",
    "    print('RandomForestClassifier')\n",
    "    print(f'Accuracy of dataframe is: {accuracy2}')\n",
    "    print(f'confusion_matrix of dataframe is:\\n {cm2}\\n')\n",
    "\n",
    "#SVM Linear, Kernel, Gaussian Kernel, Sigmoid\n",
    "def svm_func(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    kernel_hyperparameter = {'SVM':'linear', 'Kernel SVM':'poly', 'Gaussian Kernel SVM':'rbf',\n",
    "                             'Sigmoid Kernel SVM':'sigmoid'}\n",
    "    for key, value in kernel_hyperparameter.items():\n",
    "        svclassifier = SVC(kernel=value)\n",
    "        svclassifier.fit(X_train, y_train)\n",
    "        y_pred = svclassifier.predict(X_test)\n",
    "        print(f'{key}')\n",
    "        print(f'Accuracy of dataframe is: {metrics.accuracy_score(y_pred, y_test)}')\n",
    "        print(f'confusion_matrix of dataframe is:\\n {confusion_matrix(y_test,y_pred)}\\n')\n",
    "    #     print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "Accuracy of dataframe is: 0.7228033472803347\n",
      "log_reg_intercept of dataframe is: [0.58913069]\n",
      "log_reg_coef of dataframe is: [[-0.17033474 -0.39648682 -0.20847209  0.39644032  1.01672477]]\n",
      "confusion_matrix of dataframe is:\n",
      " [[467 258]\n",
      " [272 915]]\n",
      "\n",
      "Cross-validation - KFold\n",
      "> folds=2, accuracy=0.713 (0.711,0.715)\n",
      "> folds=3, accuracy=0.713 (0.706,0.721)\n",
      "> folds=4, accuracy=0.713 (0.707,0.717)\n",
      "> folds=5, accuracy=0.713 (0.704,0.721)\n",
      "> folds=6, accuracy=0.712 (0.703,0.726)\n",
      "> folds=7, accuracy=0.714 (0.704,0.723)\n",
      "> folds=8, accuracy=0.713 (0.696,0.726)\n",
      "> folds=9, accuracy=0.713 (0.693,0.730)\n",
      "> folds=10, accuracy=0.712 (0.691,0.734)\n",
      "> folds=11, accuracy=0.712 (0.693,0.739)\n",
      "> folds=12, accuracy=0.712 (0.694,0.734)\n",
      "> folds=13, accuracy=0.712 (0.684,0.747)\n",
      "> folds=14, accuracy=0.713 (0.697,0.728)\n",
      "> folds=15, accuracy=0.712 (0.694,0.738)\n",
      "> folds=16, accuracy=0.713 (0.697,0.737)\n",
      "> folds=17, accuracy=0.712 (0.690,0.742)\n",
      "> folds=18, accuracy=0.712 (0.682,0.755)\n",
      "> folds=19, accuracy=0.712 (0.688,0.736)\n",
      "> folds=20, accuracy=0.712 (0.676,0.747)\n",
      "> folds=21, accuracy=0.712 (0.675,0.741)\n",
      "> folds=22, accuracy=0.712 (0.678,0.772)\n",
      "> folds=23, accuracy=0.713 (0.671,0.745)\n",
      "> folds=24, accuracy=0.711 (0.677,0.756)\n",
      "> folds=25, accuracy=0.712 (0.679,0.767)\n",
      "> folds=26, accuracy=0.712 (0.658,0.750)\n",
      "> folds=27, accuracy=0.713 (0.675,0.774)\n",
      "> folds=28, accuracy=0.712 (0.667,0.754)\n",
      "> folds=29, accuracy=0.712 (0.661,0.751)\n",
      "> folds=30, accuracy=0.711 (0.655,0.762)\n"
     ]
    }
   ],
   "source": [
    "log_regression(df_final)\n",
    "k_fold_model(df_final, 30) # k is the fold number, here k = 30\n",
    "rand_forest(df_final)\n",
    "svm_func(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We got higher accuracy score in case of RandomForest model, so we will choose this model for predicting wine quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the results of several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "def get_dataset(df_final):\n",
    "    X = df_final.drop(\"quality\", axis = 1)\n",
    "    y = df_final[\"quality\"]\n",
    "    norm = StandardScaler().fit(X)\n",
    "    X = pd.DataFrame(columns = X.columns, data = norm.transform(X))\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression())\n",
    "    models.append(RidgeClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(LinearSVC())\n",
    "    models.append(SVC())        \n",
    "#     models.append(GaussianNB())\n",
    "#     models.append(ExtraTreesClassifier())\n",
    "#     models.append(BaggingClassifier())\n",
    "#     models.append(GaussianProcessClassifier())\n",
    "#     models.append(GradientBoostingClassifier())\n",
    "    return models\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model):\n",
    "    # get the dataset\n",
    "    X, y = get_dataset(df_final)\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores)\n",
    " \n",
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# get the list of models to consider\n",
    "models = get_models()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model)\n",
    "    # check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "    # store results\n",
    "    cv_results.append(cv_mean)\n",
    "    ideal_results.append(ideal_mean)\n",
    "    # summarize progress\n",
    "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "plt.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "plt.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "plt.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "plt.xlabel('Mean Accuracy (10-fold CV)')\n",
    "plt.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataframe):\n",
    "\n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset(df_final)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "rf=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "rf.fit(X_train,y_train)\n",
    "# save the model to disk\n",
    "filename = 'rand_forest_model.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_acidity</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0.049</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0.050</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.058</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.058</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0.050</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5776</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5364</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.069</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6110</td>\n",
       "      <td>7.47</td>\n",
       "      <td>0.078</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5855</td>\n",
       "      <td>10.39</td>\n",
       "      <td>0.088</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5679</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.114</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9561 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_acidity  chlorides    pH  sulphates  alcohol  quality\n",
       "1              6.94      0.049  3.30       0.49      9.5        1\n",
       "2              8.78      0.050  3.26       0.44     10.1        1\n",
       "3              7.75      0.058  3.19       0.40      9.9        1\n",
       "4              7.75      0.058  3.19       0.40      9.9        1\n",
       "5              8.78      0.050  3.26       0.44     10.1        1\n",
       "...             ...        ...   ...        ...      ...      ...\n",
       "5776           9.60      0.094  3.22       0.50     10.0        1\n",
       "5364          11.22      0.069  3.16       0.72     11.5        1\n",
       "6110           7.47      0.078  3.35       0.62     10.4        1\n",
       "5855          10.39      0.088  3.29       0.58     11.1        1\n",
       "5679           7.10      0.114  3.66       0.65      9.8        0\n",
       "\n",
       "[9561 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
