{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wine Quality using Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules that will be used in process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import cvxopt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# from pandas.core.common import SettingWithCopyWarning\n",
    "# warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from numpy import mean, std,isnan, asarray, polyfit\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier #SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,recall_score, precision_score,classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data set (csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have got df_final dataframe in our Getting_best_dataframe file. So here we can import our save file.\n",
    "#### df_final = pd.read_csv('Dataframe_final.csv')\n",
    "#### df_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequalityN.csv\")\n",
    "# df.sample(5)                  #shows 5 random choosen rows\n",
    "# df.head(5)                    #shows first 5 rows from data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting nomalized data from given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_correcting(data_):\n",
    "    \n",
    "    \"\"\" In dataset some values for fixed acidity, volatile acidity,\n",
    "    citric acid, residual sugar, chlorides, pH, sulphates are missing. \n",
    "    Solve this problem by filling null values with mean values of train dataframe.\n",
    "     irst of all we need to change text values of wine type to the 0 and 1.\n",
    "    Then we need to get train data and Fill Nan values by this data mean.\"\"\"\n",
    "    \n",
    "    data_[\"type\"].replace({\"red\": 0, \"white\": 1}, inplace=True) # \"RED\": 0, \"WHITE\": 1       \n",
    "    train_df = data_.sample(frac=0.8, random_state=42)\n",
    "    df.fillna(train_df.mean(axis=0), inplace=True)\n",
    "    \n",
    "    \"\"\" Now we have 1599 red and 4898 white wine rows\n",
    "    You can check it by this:\n",
    "    dups_color = df.pivot_table(index=['type'], aggfunc='size')\n",
    "    dups_color \"\"\"\n",
    "    \n",
    "    return data_\n",
    "\n",
    "df = data_correcting(df)\n",
    "\n",
    "def oversampling_data(data_):\n",
    "    \n",
    "    \"\"\" Share of white wines is 75%. So we deside to oversampling data with random choosen red wine data.\n",
    "    As in the future we can have other share of white and red wines, we get this solution for all possible cases. \"\"\"\n",
    "    \n",
    "    red_count = df.loc[data_['type'] == 0].count()[0]\n",
    "    white_count = df.loc[data_['type'] == 1].count()[0]\n",
    "    if white_count > red_count:\n",
    "        for i in range((white_count-red_count)):\n",
    "            df1 = data_.loc[data_['type'] == 0].sample()\n",
    "            data_ = data_.append(df1)\n",
    "    else:\n",
    "        for i in range((red_count-white_count)):\n",
    "            df1 = data_.loc[df['type'] == 1].sample()\n",
    "            data_ = data_.append(df1)\n",
    "            \n",
    "    \"\"\" Now combining fixed acidity, volatile acidity and citric acid into one variable total_acidity\n",
    "    and our target variable into two classes: low quality-->0 (3, 4, 5)  and high quality-->1 (6,7,8,9)\"\"\"\n",
    "    \n",
    "    data_[\"total_acidity\"]= data_['fixed acidity']+data_['volatile acidity']+data_['citric acid']\n",
    "    quaity_mapping = { 3 : 0, 4 : 0, 5: 0, 6 : 1, 7: 1, 8 : 1, 9 : 1}\n",
    "    data_[\"quality\"] =  data_[\"quality\"].map(quaity_mapping)\n",
    "    \n",
    "    \"\"\"You can check that it works by this\n",
    "    dups_color = df.pivot_table(index=['type'], aggfunc='size')\n",
    "    dups_color\n",
    "    Now we have 4898 of red and 4898 of white wines data \"\"\"\n",
    "    \n",
    "    return data_\n",
    "    \n",
    "\n",
    "# From all EDA analyze we can see that there are some outliers. So we have 2 variants\n",
    "# 1. Remove this outliers.\n",
    "# 2. Replace them with max/min values, so they may contain good values for other features and this variant will save their values\n",
    "# The whole analyse we have shown in the initial stage of project. So here we will show only the result of our final decisioans.\n",
    "# 3. Combine our target variable into two classes: low quality (3, 4, 5)  and high quality (6,7,8,9)\n",
    "\n",
    "\n",
    "def first_data(data_):\n",
    "    lower_limit = data_[\"free sulfur dioxide\"].mean() - 3*data_[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = data_[\"free sulfur dioxide\"].mean() + 3*data_[\"free sulfur dioxide\"].std()\n",
    "    df2 = data_[(data_[\"free sulfur dioxide\"] > lower_limit) & (data_[\"free sulfur dioxide\"] < upper_limit)]\n",
    "    lower_limit = df2['total sulfur dioxide'].mean() - 3*df2['total sulfur dioxide'].std()\n",
    "    upper_limit = df2['total sulfur dioxide'].mean() + 3*df2['total sulfur dioxide'].std()\n",
    "    df3 = df2[(df2['total sulfur dioxide'] > lower_limit) & (df2['total sulfur dioxide'] < upper_limit)]\n",
    "    lower_limit = df3['residual sugar'].mean() - 3*df3['residual sugar'].std()\n",
    "    upper_limit = df3['residual sugar'].mean() + 3*df3['residual sugar'].std()\n",
    "    df4 = df3[(df3['residual sugar'] > lower_limit) & (df3['residual sugar'] < upper_limit)]\n",
    "    \n",
    "    return df4\n",
    "    \n",
    "dataframe_1 = first_data(oversampling_data(df)).copy()\n",
    "\n",
    "def second_data(data_):\n",
    "    lower_limit = data_[\"free sulfur dioxide\"].mean() - 3*data_[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = data_[\"free sulfur dioxide\"].mean() + 3*data_[\"free sulfur dioxide\"].std()\n",
    "    df2_repl = data_\n",
    "    \n",
    "    def replace_outliers(arr):\n",
    "        arr = np.array(arr)\n",
    "        upper = arr.mean() + 3 * arr.std()\n",
    "        lower = arr.mean() - 3 * arr.std()\n",
    "        arr[(arr > upper)] = upper\n",
    "        arr[(arr < lower)] = lower\n",
    "        \n",
    "        return arr\n",
    "    \n",
    "    df2_repl[\"free sulfur dioxide\"] = replace_outliers(df2_repl[\"free sulfur dioxide\"])\n",
    "    df2_repl[\"total sulfur dioxide\"] = replace_outliers(df2_repl[\"total sulfur dioxide\"])\n",
    "    df2_repl[\"residual sugar\"] = replace_outliers(df2_repl[\"residual sugar\"])\n",
    "\n",
    "    lower_limit = df2_repl[\"free sulfur dioxide\"].mean() - 3*df2_repl[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = df2_repl[\"free sulfur dioxide\"].mean() + 3*df2_repl[\"free sulfur dioxide\"].std()\n",
    "    \n",
    "    return df2_repl\n",
    "\n",
    "dataframe_2 = second_data(oversampling_data(df)).copy()\n",
    "\n",
    "\n",
    "def lst_of_dataframes(d1, d2):\n",
    "    \n",
    "    \"\"\" list of dataframe_1 and dataframe_2 \"\"\"\n",
    "    \n",
    "    df_list = [d1, d2] \n",
    "    for i in range(len(df_list)):\n",
    "        df_ = df_list[i]\n",
    "        df_final = df_[[\"total_acidity\", \"chlorides\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"]]\n",
    "        df_list[i] = df_final\n",
    "        \n",
    "    return df_list\n",
    "        \n",
    "def get_dataset(dataframe):\n",
    "    \n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def checking_better_dataframe(lst):\n",
    "    \n",
    "    #lst = lst_of_dataframes(dataframe_1, dataframe_2)\n",
    "    \n",
    "    \"\"\" This function will get accuracy for two dataframes that we have, compare them\n",
    "    and return the dataframe wich gives us better accuracy. \"\"\"\n",
    "    \n",
    "    l_accuracy = []\n",
    "    \n",
    "    for i in range(len(lst)):\n",
    "        X, y = get_dataset(lst[i])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "        log_reg = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                       multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)\n",
    "        log_reg.fit(X_train,y_train)\n",
    "        y_hat = log_reg.predict(X_test)        \n",
    "        cm = confusion_matrix(y_hat,y_test)\n",
    "        accuracy = metrics.accuracy_score(y_hat,y_test)\n",
    "        l_accuracy.append(accuracy)\n",
    "#         print(f'Accuracy of dataframe_{i+1} is {accuracy}')\n",
    "#         print(f'log_reg.intercept_ of dataframe_{i+1} is {log_reg.intercept_}')\n",
    "#         print(f'log_reg.coef_ of dataframe_{i+1} is {log_reg.coef_}')\n",
    "#         print(f'confusion_matrix of dataframe_{i+1} is {cm}\\n')\n",
    "    if l_accuracy[0] > l_accuracy[1]:\n",
    "        \n",
    "        return lst[0]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return lst[1]\n",
    "        \n",
    "df_final = checking_better_dataframe(lst_of_dataframes(dataframe_1, dataframe_2))[[\"total_acidity\", \"chlorides\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have 2 datasets for modeling\n",
    "#### 1.1) dataframe_1 (where outliers removed, quality scaled to 2 types)\n",
    "#### 1.2) dataframe_2 (where outliers replaced with mean values, quality scaled to 2 types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic regression\n",
    "# 2. Cross-validation - KFold\n",
    "# 3. RandomForestClassifier\n",
    "# 4. SVM\n",
    "# 5. Kernel SVM\n",
    "# 6. Gaussian Kernel\n",
    "# 7. Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the dataset transformation function\n",
    "def get_dataset(dataframe):\n",
    "\n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def log_regression(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    #Logistic regression\n",
    "    log_reg = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                       multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)\n",
    "    log_reg.fit(X_train,y_train)\n",
    "    y_hat = log_reg.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_hat,y_test)\n",
    "    cm = confusion_matrix(y_hat,y_test)\n",
    "    # Let's predict target values for test dataset and check model accuracy\n",
    "    print('Logistic regression')\n",
    "    print(f'Accuracy of dataframe is: {accuracy}')\n",
    "    print(f'log_reg_intercept of dataframe is: {log_reg.intercept_}')\n",
    "    print(f'log_reg_coef of dataframe is: {log_reg.coef_}')\n",
    "    print(f'confusion_matrix of dataframe is:\\n {cm}\\n')\n",
    "\n",
    "#Cross-validation - KFold\n",
    "def k_fold_model(dataframe, k):\n",
    "    X, y = get_dataset(dataframe)\n",
    "\n",
    "    # retrieve the model to be evaluate\n",
    "    def get_model():\n",
    "        model = LogisticRegression()\n",
    "        return model\n",
    "\n",
    "    # evaluate the model using a given test condition\n",
    "    def evaluate_model(cv):\n",
    "        # get the dataset\n",
    "        #X, y = fit_dataset(dataframe)\n",
    "        # get the model\n",
    "        model = get_model()\n",
    "        # evaluate the model\n",
    "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        # return scores\n",
    "        return mean(scores), scores.min(), scores.max()\n",
    "\n",
    "\n",
    "    print('Cross-validation - KFold')\n",
    "    # define folds to test\n",
    "    folds = range(2, k+1)\n",
    "\n",
    "    # record mean and min/max of each set of results\n",
    "    means, mins, maxs = list(),list(),list()\n",
    "    # evaluate each k value\n",
    "    for k in folds:\n",
    "        # define the test condition\n",
    "        cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "        # evaluate k value\n",
    "        k_mean, k_min, k_max = evaluate_model(cv)\n",
    "        # report performance        \n",
    "        print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "        # store mean accuracy\n",
    "        means.append(k_mean)\n",
    "        # store min and max relative to the mean\n",
    "        mins.append(k_mean - k_min)\n",
    "        maxs.append(k_max - k_mean)\n",
    "    # calculate the ideal test condition\n",
    "    ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "    print()\n",
    "    print('Ideal: %.3f' % ideal)\n",
    "    print()\n",
    "\n",
    "#RandomForestClassifier\n",
    "def rand_forest(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    rf=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                           criterion='gini', max_depth=None, max_features='auto',\n",
    "                           max_leaf_nodes=None, max_samples=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_jobs=None, oob_score=False, random_state=None,\n",
    "                           verbose=0, warm_start=False)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred=rf.predict(X_test)\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    accuracy2 = metrics.accuracy_score(y_pred, y_test)\n",
    "    cm2 = confusion_matrix(y_pred,y_test)\n",
    "    print('RandomForestClassifier')\n",
    "    print(f'Accuracy of dataframe is: {accuracy2}')\n",
    "    print(f'confusion_matrix of dataframe is:\\n {cm2}\\n')\n",
    "\n",
    "#SVM Linear, Kernel, Gaussian Kernel, Sigmoid\n",
    "def svm_func(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    kernel_hyperparameter = {'SVM':'linear', 'Kernel SVM':'poly', 'Gaussian Kernel SVM':'rbf',\n",
    "                             'Sigmoid Kernel SVM':'sigmoid'}\n",
    "    for key, value in kernel_hyperparameter.items():\n",
    "        svclassifier = SVC(kernel=value)\n",
    "        svclassifier.fit(X_train, y_train)\n",
    "        y_pred = svclassifier.predict(X_test)\n",
    "        print(f'{key}')\n",
    "        print(f'Accuracy of dataframe is: {metrics.accuracy_score(y_pred, y_test)}')\n",
    "        print(f'confusion_matrix of dataframe is:\\n {confusion_matrix(y_test,y_pred)}\\n')\n",
    "    #     print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "Accuracy of dataframe is: 0.7128661087866108\n",
      "log_reg_intercept of dataframe is: [0.58311676]\n",
      "log_reg_coef of dataframe is: [[-0.21173889 -0.34757642 -0.2732999   0.44150621  0.98037735]]\n",
      "confusion_matrix of dataframe is:\n",
      " [[449 260]\n",
      " [289 914]]\n",
      "\n",
      "Cross-validation - KFold\n",
      "> folds=2, accuracy=0.702 (0.702,0.702)\n",
      "> folds=3, accuracy=0.703 (0.697,0.708)\n",
      "> folds=4, accuracy=0.703 (0.693,0.709)\n",
      "> folds=5, accuracy=0.702 (0.691,0.718)\n",
      "> folds=6, accuracy=0.703 (0.685,0.709)\n",
      "> folds=7, accuracy=0.701 (0.683,0.711)\n",
      "> folds=8, accuracy=0.702 (0.685,0.715)\n",
      "> folds=9, accuracy=0.702 (0.684,0.712)\n",
      "> folds=10, accuracy=0.703 (0.675,0.724)\n",
      "> folds=11, accuracy=0.702 (0.663,0.726)\n",
      "> folds=12, accuracy=0.702 (0.685,0.716)\n",
      "> folds=13, accuracy=0.702 (0.663,0.728)\n",
      "> folds=14, accuracy=0.702 (0.663,0.720)\n",
      "> folds=15, accuracy=0.703 (0.670,0.738)\n",
      "> folds=16, accuracy=0.703 (0.670,0.724)\n",
      "> folds=17, accuracy=0.703 (0.657,0.738)\n",
      "> folds=18, accuracy=0.703 (0.659,0.736)\n",
      "> folds=19, accuracy=0.703 (0.660,0.734)\n",
      "> folds=20, accuracy=0.703 (0.651,0.738)\n",
      "> folds=21, accuracy=0.703 (0.664,0.734)\n",
      "> folds=22, accuracy=0.703 (0.654,0.736)\n",
      "> folds=23, accuracy=0.703 (0.634,0.742)\n",
      "> folds=24, accuracy=0.703 (0.661,0.734)\n",
      "> folds=25, accuracy=0.703 (0.652,0.733)\n",
      "> folds=26, accuracy=0.703 (0.621,0.734)\n",
      "> folds=27, accuracy=0.703 (0.653,0.734)\n",
      "> folds=28, accuracy=0.702 (0.655,0.742)\n",
      "> folds=29, accuracy=0.703 (0.641,0.736)\n",
      "> folds=30, accuracy=0.703 (0.654,0.749)\n",
      "\n",
      "Ideal: 0.704\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy of dataframe is: 0.8917364016736402\n",
      "confusion_matrix of dataframe is:\n",
      " [[ 613   82]\n",
      " [ 125 1092]]\n",
      "\n",
      "SVM\n",
      "Accuracy of dataframe is: 0.7170502092050209\n",
      "confusion_matrix of dataframe is:\n",
      " [[512 226]\n",
      " [315 859]]\n",
      "\n",
      "Kernel SVM\n",
      "Accuracy of dataframe is: 0.6814853556485355\n",
      "confusion_matrix of dataframe is:\n",
      " [[ 224  514]\n",
      " [  95 1079]]\n",
      "\n",
      "Gaussian Kernel SVM\n",
      "Accuracy of dataframe is: 0.7473849372384938\n",
      "confusion_matrix of dataframe is:\n",
      " [[482 256]\n",
      " [227 947]]\n",
      "\n",
      "Sigmoid Kernel SVM\n",
      "Accuracy of dataframe is: 0.6239539748953975\n",
      "confusion_matrix of dataframe is:\n",
      " [[387 351]\n",
      " [368 806]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_regression(df_final)\n",
    "k_fold_model(df_final, 30) # k is the fold number, here k = 30\n",
    "rand_forest(df_final)\n",
    "svm_func(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We got higher accuracy score in case of RandomForest model, so we will choose this model for predicting wine quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the results of several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LogisticRegression: ideal=0.716, cv=0.715\n",
      ">RidgeClassifier: ideal=0.711, cv=0.713\n",
      ">KNeighborsClassifier: ideal=0.825, cv=0.820\n",
      ">DecisionTreeClassifier: ideal=0.877, cv=0.869\n",
      ">RandomForestClassifier: ideal=0.902, cv=0.890\n",
      ">LinearSVC: ideal=0.712, cv=0.712\n",
      ">SVC: ideal=0.752, cv=0.751\n",
      "Correlation: 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the dataset\n",
    "def get_dataset(df_final):\n",
    "    X = df_final.drop(\"quality\", axis = 1)\n",
    "    y = df_final[\"quality\"]\n",
    "    norm = StandardScaler().fit(X)\n",
    "    X = pd.DataFrame(columns = X.columns, data = norm.transform(X))\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression())\n",
    "    models.append(RidgeClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(LinearSVC())\n",
    "    models.append(SVC())        \n",
    "#     models.append(GaussianNB())\n",
    "#     models.append(ExtraTreesClassifier())\n",
    "#     models.append(BaggingClassifier())\n",
    "#     models.append(GaussianProcessClassifier())\n",
    "#     models.append(GradientBoostingClassifier())\n",
    "    return models\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model):\n",
    "    # get the dataset\n",
    "    X, y = get_dataset(df_final)\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores)\n",
    " \n",
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# get the list of models to consider\n",
    "models = get_models()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model)\n",
    "    # check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "    # store results\n",
    "    cv_results.append(cv_mean)\n",
    "    ideal_results.append(ideal_mean)\n",
    "    # summarize progress\n",
    "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "plt.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "plt.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "plt.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "plt.xlabel('Mean Accuracy (10-fold CV)')\n",
    "plt.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifierÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataframe):\n",
    "\n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset(df_final)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "rf=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "rf.fit(X_train,y_train)\n",
    "# save the model to disk\n",
    "filename = 'instance.json'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
