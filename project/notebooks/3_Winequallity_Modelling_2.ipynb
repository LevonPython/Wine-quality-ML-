{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wine Quality using Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules that will be used in process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import cvxopt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# from pandas.core.common import SettingWithCopyWarning\n",
    "# warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from numpy import mean, std,isnan, asarray, polyfit\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier #SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,recall_score, precision_score,classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data set (csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have got df_final dataframe in our Getting_best_dataframe file. So here we can import our save file.\n",
    "#### df_final = pd.read_csv('Dataframe_final.csv')\n",
    "#### df_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequalityN.csv\")\n",
    "# df.sample(5)                  #shows 5 random choosen rows\n",
    "# df.head(5)                    #shows first 5 rows from data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting normalized data from given dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_correcting(data_):\n",
    "    \n",
    "    \"\"\" In dataset some values for fixed acidity, volatile acidity,\n",
    "    citric acid, residual sugar, chlorides, pH, sulphates are missing. \n",
    "    Solve this problem by filling null values with mean values of train dataframe.\n",
    "     irst of all we need to change text values of wine type to the 0 and 1.\n",
    "    Then we need to get train data and Fill Nan values by this data mean.\"\"\"\n",
    "    \n",
    "    data_[\"type\"].replace({\"red\": 0, \"white\": 1}, inplace=True) # \"RED\": 0, \"WHITE\": 1       \n",
    "    train_df = data_.sample(frac=0.8, random_state=42)\n",
    "    df.fillna(train_df.mean(axis=0), inplace=True)\n",
    "    \n",
    "    \"\"\" Now we have 1599 red and 4898 white wine rows\n",
    "    You can check it by this:\n",
    "    dups_color = df.pivot_table(index=['type'], aggfunc='size')\n",
    "    dups_color \"\"\"\n",
    "    \n",
    "    return data_\n",
    "\n",
    "df = data_correcting(df)\n",
    "\n",
    "def oversampling_data(data_):\n",
    "    \n",
    "    \"\"\" Share of white wines is 75%. So we deside to oversampling data with random choosen red wine data.\n",
    "    As in the future we can have other share of white and red wines, we get this solution for all possible cases. \"\"\"\n",
    "    \n",
    "    red_count = df.loc[data_['type'] == 0].count()[0]\n",
    "    white_count = df.loc[data_['type'] == 1].count()[0]\n",
    "    if white_count > red_count:\n",
    "        for i in range((white_count-red_count)):\n",
    "            df1 = data_.loc[data_['type'] == 0].sample()\n",
    "            data_ = data_.append(df1)\n",
    "    else:\n",
    "        for i in range((red_count-white_count)):\n",
    "            df1 = data_.loc[df['type'] == 1].sample()\n",
    "            data_ = data_.append(df1)\n",
    "            \n",
    "    \"\"\" Now combining fixed acidity, volatile acidity and citric acid into one variable total_acidity\n",
    "    and our target variable into two classes: low quality-->0 (3, 4, 5)  and high quality-->1 (6,7,8,9)\"\"\"\n",
    "    \n",
    "    data_[\"total_acidity\"]= data_['fixed acidity']+data_['volatile acidity']+data_['citric acid']\n",
    "    quaity_mapping = { 3 : 0, 4 : 0, 5: 0, 6 : 1, 7: 1, 8 : 1, 9 : 1}\n",
    "    data_[\"quality\"] =  data_[\"quality\"].map(quaity_mapping)\n",
    "    \n",
    "    \"\"\"You can check that it works by this\n",
    "    dups_color = df.pivot_table(index=['type'], aggfunc='size')\n",
    "    dups_color\n",
    "    Now we have 4898 of red and 4898 of white wines data \"\"\"\n",
    "    \n",
    "    return data_\n",
    "    \n",
    "\n",
    "# From all EDA analyze we can see that there are some outliers. So we have 2 variants\n",
    "# 1. Remove this outliers.\n",
    "# 2. Replace them with max/min values, so they may contain good values for other features and this variant will save their values\n",
    "# The whole analyse we have shown in the initial stage of project. So here we will show only the result of our final decisioans.\n",
    "# 3. Combine our target variable into two classes: low quality (3, 4, 5)  and high quality (6,7,8,9)\n",
    "\n",
    "\n",
    "def first_data(data_):\n",
    "    lower_limit = data_[\"free sulfur dioxide\"].mean() - 3*data_[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = data_[\"free sulfur dioxide\"].mean() + 3*data_[\"free sulfur dioxide\"].std()\n",
    "    df2 = data_[(data_[\"free sulfur dioxide\"] > lower_limit) & (data_[\"free sulfur dioxide\"] < upper_limit)]\n",
    "    lower_limit = df2['total sulfur dioxide'].mean() - 3*df2['total sulfur dioxide'].std()\n",
    "    upper_limit = df2['total sulfur dioxide'].mean() + 3*df2['total sulfur dioxide'].std()\n",
    "    df3 = df2[(df2['total sulfur dioxide'] > lower_limit) & (df2['total sulfur dioxide'] < upper_limit)]\n",
    "    lower_limit = df3['residual sugar'].mean() - 3*df3['residual sugar'].std()\n",
    "    upper_limit = df3['residual sugar'].mean() + 3*df3['residual sugar'].std()\n",
    "    df4 = df3[(df3['residual sugar'] > lower_limit) & (df3['residual sugar'] < upper_limit)]\n",
    "    \n",
    "    return df4\n",
    "    \n",
    "dataframe_1 = first_data(oversampling_data(df)).copy()\n",
    "\n",
    "def second_data(data_):\n",
    "    lower_limit = data_[\"free sulfur dioxide\"].mean() - 3*data_[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = data_[\"free sulfur dioxide\"].mean() + 3*data_[\"free sulfur dioxide\"].std()\n",
    "    df2_repl = data_\n",
    "    \n",
    "    def replace_outliers(arr):\n",
    "        arr = np.array(arr)\n",
    "        upper = arr.mean() + 3 * arr.std()\n",
    "        lower = arr.mean() - 3 * arr.std()\n",
    "        arr[(arr > upper)] = upper\n",
    "        arr[(arr < lower)] = lower\n",
    "        \n",
    "        return arr\n",
    "    \n",
    "    df2_repl[\"free sulfur dioxide\"] = replace_outliers(df2_repl[\"free sulfur dioxide\"])\n",
    "    df2_repl[\"total sulfur dioxide\"] = replace_outliers(df2_repl[\"total sulfur dioxide\"])\n",
    "    df2_repl[\"residual sugar\"] = replace_outliers(df2_repl[\"residual sugar\"])\n",
    "\n",
    "    lower_limit = df2_repl[\"free sulfur dioxide\"].mean() - 3*df2_repl[\"free sulfur dioxide\"].std()\n",
    "    upper_limit = df2_repl[\"free sulfur dioxide\"].mean() + 3*df2_repl[\"free sulfur dioxide\"].std()\n",
    "    \n",
    "    return df2_repl\n",
    "\n",
    "dataframe_2 = second_data(oversampling_data(df)).copy()\n",
    "\n",
    "\n",
    "def lst_of_dataframes(d1, d2):\n",
    "    \n",
    "    \"\"\" list of dataframe_1 and dataframe_2 \"\"\"\n",
    "    \n",
    "    df_list = [d1, d2] \n",
    "    for i in range(len(df_list)):\n",
    "        df_ = df_list[i]\n",
    "        df_final = df_[[\"total_acidity\", \"chlorides\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"]]\n",
    "        df_list[i] = df_final\n",
    "        \n",
    "    return df_list\n",
    "        \n",
    "def get_dataset(dataframe):\n",
    "    \n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def checking_better_dataframe(lst):\n",
    "    \n",
    "    #lst = lst_of_dataframes(dataframe_1, dataframe_2)\n",
    "    \n",
    "    \"\"\" This function will get accuracy for two dataframes that we have, compare them\n",
    "    and return the dataframe wich gives us better accuracy. \"\"\"\n",
    "    \n",
    "    l_accuracy = []\n",
    "    \n",
    "    for i in range(len(lst)):\n",
    "        X, y = get_dataset(lst[i])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "        log_reg = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                       multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)\n",
    "        log_reg.fit(X_train,y_train)\n",
    "        y_hat = log_reg.predict(X_test)        \n",
    "        cm = confusion_matrix(y_hat,y_test)\n",
    "        accuracy = metrics.accuracy_score(y_hat,y_test)\n",
    "        l_accuracy.append(accuracy)\n",
    "#         print(f'Accuracy of dataframe_{i+1} is {accuracy}')\n",
    "#         print(f'log_reg.intercept_ of dataframe_{i+1} is {log_reg.intercept_}')\n",
    "#         print(f'log_reg.coef_ of dataframe_{i+1} is {log_reg.coef_}')\n",
    "#         print(f'confusion_matrix of dataframe_{i+1} is {cm}\\n')\n",
    "    if l_accuracy[0] > l_accuracy[1]:\n",
    "        \n",
    "        return lst[0]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return lst[1]\n",
    "        \n",
    "df_final = checking_better_dataframe(lst_of_dataframes(dataframe_1, dataframe_2))[[\"total_acidity\", \"chlorides\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have 2 datasets for modeling\n",
    "#### 1.1) dataframe_1 (where outliers removed, quality scaled to 2 types)\n",
    "#### 1.2) dataframe_2 (where outliers replaced with mean values, quality scaled to 2 types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic regression\n",
    "# 2. Cross-validation - KFold\n",
    "# 3. RandomForestClassifier\n",
    "# 4. SVM\n",
    "# 5. Kernel SVM\n",
    "# 6. Gaussian Kernel\n",
    "# 7. Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset transformation function\n",
    "def get_dataset(dataframe):\n",
    "\n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def log_regression(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    #Logistic regression\n",
    "    log_reg = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                       intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                       multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                       warm_start=False)\n",
    "    log_reg.fit(X_train,y_train)\n",
    "    y_hat = log_reg.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_hat,y_test)\n",
    "    cm = confusion_matrix(y_hat,y_test)\n",
    "    # Let's predict target values for test dataset and check model accuracy\n",
    "    print('Logistic regression')\n",
    "    print(f'Accuracy of dataframe is: {accuracy}')\n",
    "    print(f'log_reg_intercept of dataframe is: {log_reg.intercept_}')\n",
    "    print(f'log_reg_coef of dataframe is: {log_reg.coef_}')\n",
    "    print(f'confusion_matrix of dataframe is:\\n {cm}\\n')\n",
    "\n",
    "#Cross-validation - KFold\n",
    "def k_fold_model(dataframe, k):\n",
    "    X, y = get_dataset(dataframe)\n",
    "\n",
    "    # retrieve the model to be evaluate\n",
    "    def get_model():\n",
    "        model = LogisticRegression()\n",
    "        return model\n",
    "\n",
    "    # evaluate the model using a given test condition\n",
    "    def evaluate_model(cv):\n",
    "        # get the dataset\n",
    "        #X, y = fit_dataset(dataframe)\n",
    "        # get the model\n",
    "        model = get_model()\n",
    "        # evaluate the model\n",
    "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        # return scores\n",
    "        return mean(scores), scores.min(), scores.max()\n",
    "\n",
    "\n",
    "    print('Cross-validation - KFold')\n",
    "    # define folds to test\n",
    "    folds = range(2, k+1)\n",
    "\n",
    "    # record mean and min/max of each set of results\n",
    "    means, mins, maxs = list(),list(),list()\n",
    "    # evaluate each k value\n",
    "    for k in folds:\n",
    "        # define the test condition\n",
    "        cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "        # evaluate k value\n",
    "        k_mean, k_min, k_max = evaluate_model(cv)\n",
    "        # report performance        \n",
    "        print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "        # store mean accuracy\n",
    "        means.append(k_mean)\n",
    "        # store min and max relative to the mean\n",
    "        mins.append(k_mean - k_min)\n",
    "        maxs.append(k_max - k_mean)\n",
    "    # calculate the ideal test condition\n",
    "    ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "    print()\n",
    "    print('Ideal: %.3f' % ideal)\n",
    "    print()\n",
    "\n",
    "#RandomForestClassifier\n",
    "def rand_forest(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    rf=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                           criterion='gini', max_depth=None, max_features='auto',\n",
    "                           max_leaf_nodes=None, max_samples=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_jobs=None, oob_score=False, random_state=None,\n",
    "                           verbose=0, warm_start=False)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred=rf.predict(X_test)\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    accuracy2 = metrics.accuracy_score(y_pred, y_test)\n",
    "    cm2 = confusion_matrix(y_pred,y_test)\n",
    "    print('RandomForestClassifier')\n",
    "    print(f'Accuracy of dataframe is: {accuracy2}')\n",
    "    print(f'confusion_matrix of dataframe is:\\n {cm2}\\n')\n",
    "\n",
    "#SVM Linear, Kernel, Gaussian Kernel, Sigmoid\n",
    "def svm_func(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    kernel_hyperparameter = {'SVM':'linear', 'Kernel SVM':'poly', 'Gaussian Kernel SVM':'rbf',\n",
    "                             'Sigmoid Kernel SVM':'sigmoid'}\n",
    "    for key, value in kernel_hyperparameter.items():\n",
    "        svclassifier = SVC(kernel=value)\n",
    "        svclassifier.fit(X_train, y_train)\n",
    "        y_pred = svclassifier.predict(X_test)\n",
    "        print(f'{key}')\n",
    "        print(f'Accuracy of dataframe is: {metrics.accuracy_score(y_pred, y_test)}')\n",
    "        print(f'confusion_matrix of dataframe is:\\n {confusion_matrix(y_test,y_pred)}\\n')\n",
    "    #     print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "Accuracy of dataframe is: 0.7207112970711297\n",
      "log_reg_intercept of dataframe is: [0.6087698]\n",
      "log_reg_coef of dataframe is: [[-0.16394986 -0.36181396 -0.2563822   0.44620045  0.98329446]]\n",
      "confusion_matrix of dataframe is:\n",
      " [[465 232]\n",
      " [302 913]]\n",
      "\n",
      "Cross-validation - KFold\n",
      "> folds=2, accuracy=0.708 (0.697,0.719)\n",
      "> folds=3, accuracy=0.707 (0.691,0.721)\n",
      "> folds=4, accuracy=0.707 (0.687,0.728)\n",
      "> folds=5, accuracy=0.706 (0.685,0.729)\n",
      "> folds=6, accuracy=0.707 (0.685,0.731)\n",
      "> folds=7, accuracy=0.706 (0.686,0.733)\n",
      "> folds=8, accuracy=0.707 (0.679,0.739)\n",
      "> folds=9, accuracy=0.707 (0.671,0.735)\n",
      "> folds=10, accuracy=0.706 (0.675,0.734)\n",
      "> folds=11, accuracy=0.707 (0.672,0.736)\n",
      "> folds=12, accuracy=0.706 (0.676,0.741)\n",
      "> folds=13, accuracy=0.706 (0.679,0.751)\n",
      "> folds=14, accuracy=0.706 (0.682,0.751)\n",
      "> folds=15, accuracy=0.707 (0.676,0.754)\n",
      "> folds=16, accuracy=0.706 (0.659,0.750)\n",
      "> folds=17, accuracy=0.707 (0.673,0.747)\n",
      "> folds=18, accuracy=0.707 (0.661,0.755)\n",
      "> folds=19, accuracy=0.706 (0.668,0.755)\n",
      "> folds=20, accuracy=0.706 (0.669,0.753)\n",
      "> folds=21, accuracy=0.706 (0.664,0.758)\n",
      "> folds=22, accuracy=0.706 (0.666,0.758)\n",
      "> folds=23, accuracy=0.706 (0.661,0.754)\n",
      "> folds=24, accuracy=0.707 (0.657,0.764)\n",
      "> folds=25, accuracy=0.707 (0.648,0.764)\n",
      "> folds=26, accuracy=0.706 (0.647,0.766)\n",
      "> folds=27, accuracy=0.707 (0.661,0.766)\n",
      "> folds=28, accuracy=0.707 (0.661,0.765)\n",
      "> folds=29, accuracy=0.707 (0.658,0.760)\n",
      "> folds=30, accuracy=0.707 (0.664,0.758)\n",
      "\n",
      "Ideal: 0.707\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy of dataframe is: 0.8849372384937239\n",
      "confusion_matrix of dataframe is:\n",
      " [[ 635   88]\n",
      " [ 132 1057]]\n",
      "\n",
      "SVM\n",
      "Accuracy of dataframe is: 0.7248953974895398\n",
      "confusion_matrix of dataframe is:\n",
      " [[531 236]\n",
      " [290 855]]\n",
      "\n",
      "Kernel SVM\n",
      "Accuracy of dataframe is: 0.6752092050209205\n",
      "confusion_matrix of dataframe is:\n",
      " [[ 212  555]\n",
      " [  66 1079]]\n",
      "\n",
      "Gaussian Kernel SVM\n",
      "Accuracy of dataframe is: 0.752092050209205\n",
      "confusion_matrix of dataframe is:\n",
      " [[490 277]\n",
      " [197 948]]\n",
      "\n",
      "Sigmoid Kernel SVM\n",
      "Accuracy of dataframe is: 0.6323221757322176\n",
      "confusion_matrix of dataframe is:\n",
      " [[405 362]\n",
      " [341 804]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_regression(df_final)\n",
    "k_fold_model(df_final, 30) # k is the fold number, here k = 30\n",
    "rand_forest(df_final)\n",
    "svm_func(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We got higher accuracy score in case of RandomForest model, so we will choose this model for predicting wine quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the results of several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">LogisticRegression: ideal=0.707, cv=0.706\n",
      ">RidgeClassifier: ideal=0.708, cv=0.707\n",
      ">KNeighborsClassifier: ideal=0.821, cv=0.815\n",
      ">DecisionTreeClassifier: ideal=0.873, cv=0.876\n",
      ">RandomForestClassifier: ideal=0.903, cv=0.898\n",
      ">LinearSVC: ideal=0.706, cv=0.706\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "def get_dataset(df_final):\n",
    "    X = df_final.drop(\"quality\", axis = 1)\n",
    "    y = df_final[\"quality\"]\n",
    "    norm = StandardScaler().fit(X)\n",
    "    X = pd.DataFrame(columns = X.columns, data = norm.transform(X))\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LogisticRegression())\n",
    "    models.append(RidgeClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(LinearSVC())\n",
    "    models.append(SVC())        \n",
    "#     models.append(GaussianNB())\n",
    "#     models.append(ExtraTreesClassifier())\n",
    "#     models.append(BaggingClassifier())\n",
    "#     models.append(GaussianProcessClassifier())\n",
    "#     models.append(GradientBoostingClassifier())\n",
    "    return models\n",
    " \n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model):\n",
    "    # get the dataset\n",
    "    X, y = get_dataset(df_final)\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores)\n",
    " \n",
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# get the list of models to consider\n",
    "models = get_models()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "# evaluate each model\n",
    "for model in models:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model)\n",
    "    # check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "    # store results\n",
    "    cv_results.append(cv_mean)\n",
    "    ideal_results.append(ideal_mean)\n",
    "    # summarize progress\n",
    "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "plt.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "plt.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "plt.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "plt.xlabel('Mean Accuracy (10-fold CV)')\n",
    "plt.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we also got higher accuracy score in case of RandomForest model, so we will choose this model for predicting wine quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataframe):\n",
    "\n",
    "    X = dataframe.drop(\"quality\", axis = 1)\n",
    "    y = dataframe[\"quality\"]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset(df_final)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "rf=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "rf.fit(X_train,y_train)\n",
    "# save the model to disk\n",
    "filename = 'instance.json'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best model is Cross-validation-KFold for Random Forest Classifier model, but our computers need more time for   it. So we just write a code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validation - KFold\n",
    "def k_fold_model(dataframe):\n",
    "    X, y = get_dataset(dataframe)\n",
    "    # retrieve the model to be evaluate\n",
    "    def get_model():\n",
    "        model = RandomForestClassifier()\n",
    "        return model\n",
    "    # evaluate the model using a given test condition\n",
    "    def evaluate_model(cv):\n",
    "        # get the dataset\n",
    "        #X, y = fit_dataset(dataframe)\n",
    "        # get the model\n",
    "        model = get_model()\n",
    "        # evaluate the model\n",
    "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        # return scores\n",
    "        return mean(scores), scores.min(), scores.max()\n",
    "    print('Cross-validation - KFold-RandomForestClassifier')\n",
    "    # define folds to test\n",
    "    folds = range(2, 11)\n",
    "    # record mean and min/max of each set of results\n",
    "    means, mins, maxs = list(),list(),list()\n",
    "    # evaluate each k value\n",
    "    for k in folds:\n",
    "        # define the test condition\n",
    "        cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        # evaluate k value\n",
    "        k_mean, k_min, k_max = evaluate_model(cv)\n",
    "        # report performance\n",
    "        # print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "        # store mean accuracy\n",
    "        means.append(k_mean)\n",
    "        # store min and max relative to the mean\n",
    "        mins.append(k_mean - k_min)\n",
    "        maxs.append(k_max - k_mean)\n",
    "    # calculate the ideal test condition\n",
    "    ideal, _, _ = evaluate_model(LeaveOneOut())\n",
    "    print()\n",
    "    print('Ideal: %.3f' % ideal)\n",
    "    print()\n",
    "    # save the model to disk\n",
    "    filename = 'instance.json'\n",
    "    pickle.dump(get_model(), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
